{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\ProgramData\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#改查詢\n",
    "import time\n",
    "import json\n",
    "import unicodedata​import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#改查詢\n",
    "import time\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "import xlwt\n",
    "import xlrd\n",
    "\n",
    "  \n",
    "workbook = xlwt.Workbook(encoding='utf-8')  \n",
    "booksheet = workbook.add_sheet('Sheet 1', cell_overwrite_ok=True)  \n",
    "#write dict\n",
    "\n",
    "\n",
    "\n",
    "res= requests.get(\"http://sports.williamhill.com/bet/zh-hk/betting/g/6740/%E7%8D%A8%E8%B4%8F%E7%9B%A4.html\")\n",
    "soup=BeautifulSoup(res.text)\n",
    "\n",
    "import xlwt\n",
    "import xlrd\n",
    "\n",
    "  \n",
    "workbook = xlwt.Workbook(encoding='utf-8')  \n",
    "booksheet = workbook.add_sheet('Sheet 1', cell_overwrite_ok=True)  \n",
    "#write dict\n",
    "\n",
    "\n",
    "\n",
    "res= requests.get(\"http://sports.williamhill.com/bet/zh-hk/betting/g/6740/%E7%8D%A8%E8%B4%8F%E7%9B%A4.html\")\n",
    "soup=BeautifulSoup(res.text)\n",
    "\n",
    "match=len(soup.findAll(\"td\",{\"class\":\"CentrePad\"}))\n",
    "\n",
    "\n",
    "\n",
    "def l1():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[6].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[7].text[19:23])\n",
    "    return k\n",
    "\n",
    "def l2():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[8].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[9].text[19:23])\n",
    "    return k \n",
    "def l3():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[10].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[11].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l4():  \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[4].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[5].text[19:23])\n",
    "    return k \n",
    "    \n",
    "\n",
    "def l5(): \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[2].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[3].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l6():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[0].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[1].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "def l7():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[12].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[13].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "def l8():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[14].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[15].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l9():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[16].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[17].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l10():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[18].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[19].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l11():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[20].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[21].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "def l12():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[22].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[23].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l13():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[24].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[25].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l14():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[26].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[27].text[19:23])\n",
    "    return k \n",
    "def l15():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[28].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[29].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "def dictinal1():\n",
    "    a=dict()\n",
    "    if match>=1:\n",
    "        a[unicodedata.normalize(\"NFKD\",soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0] .text.strip('\\n').replace('\\n', ''))]=l6() \n",
    "    if match>=2:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[1].text.strip('\\n').replace('\\n', ''))]=l5()     \n",
    "    if match>=3:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2].text.strip('\\n').replace('\\n', ''))]=l4()\n",
    "    if match>=4:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[3].text.strip('\\n').replace('\\n', ''))]=l1()   \n",
    "    if match>=5:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4].text.strip('\\n').replace('\\n', ''))]=l2()   \n",
    "    if match>=6:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[5].text.strip('\\n').replace('\\n', ''))]=l3()  \n",
    "    if match>=7:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[6].text.strip('\\n').replace('\\n', ''))]=l7() \n",
    "    if match>=8:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[7].text.strip('\\n').replace('\\n', ''))]=l8()     \n",
    "    if match>=9:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[8].text.strip('\\n').replace('\\n', ''))]=l9()\n",
    "    if match>=10:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[9].text.strip('\\n').replace('\\n', ''))]=l10()   \n",
    "    if match>=11:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[10].text.strip('\\n').replace('\\n', ''))]=l11()   \n",
    "    if match>=12:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[11].text.strip('\\n').replace('\\n', ''))]=l12() \n",
    "    if match>=13:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[12].text.strip('\\n').replace('\\n', ''))]=l13()\n",
    "    if match>=14:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[13].text.strip('\\n').replace('\\n', ''))]=l14()\n",
    "    if match>=15:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[14].text.strip('\\n').replace('\\n', ''))]=l15()\n",
    "    \n",
    "        \n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(list(dictinal1().keys()))):\n",
    "    booksheet.write(i,0,list(dictinal1().keys())[i])\n",
    "    booksheet.write(i,1,dictinal1()[list(dictinal1().keys())[i]][0])\n",
    "    booksheet.write(i,2,dictinal1()[list(dictinal1().keys())[i]][1])\n",
    "    \n",
    "res= requests.get(\"http://sports.williamhill.com/bet/zh-hk/betting/g/9387/%E8%AE%93%E5%88%86%E7%9B%A4.html\")\n",
    "soup=BeautifulSoup(res.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "match=len(soup.findAll(\"td\",{\"class\":\"CentrePad\"}))\n",
    "\n",
    "\n",
    "def l1():   \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[6].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[7].text[19:23]))\n",
    "    return k\n",
    "\n",
    "def l2():   \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[8].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[9].text[19:23]))\n",
    "    return k \n",
    "def l3():   \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[10].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[11].text[19:23]))\n",
    "    return k \n",
    "\n",
    "def l4():  \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[4].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[5].text[19:23]))\n",
    "    return k \n",
    "    \n",
    "\n",
    "def l5(): \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[2].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[3].text[19:23]))\n",
    "    return k \n",
    "\n",
    "def l6():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[0].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[1].text[19:23]))\n",
    "    return k \n",
    "\n",
    "\n",
    "def l7():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[12].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[13].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "def l8():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[14].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[15].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l9():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[16].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[17].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l10():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[18].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[19].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l11():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[20].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[21].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "def l12():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[22].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[23].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l13():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[24].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[25].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "def l14():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[26].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[27].text[19:23])\n",
    "    return k \n",
    "def l15():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[28].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[29].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "def dictinal2():\n",
    "    a=dict()\n",
    "    if match>=1:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l6() \n",
    "    if match>=2:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[1].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l5()     \n",
    "    if match>=3:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l4()   \n",
    "    if match>=4:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[3].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l1()   \n",
    "    if match>=5:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l2()   \n",
    "    if match>=6:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[5].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l3()    \n",
    "    if match>=7:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[6].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l7() \n",
    "    if match>=8:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[7].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l8()     \n",
    "    if match>=9:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[8].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l9()   \n",
    "    if match>=10:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[9].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l10()   \n",
    "    if match>=11:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[10].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l11()   \n",
    "    if match>=12:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[11].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l12()    \n",
    "    if match>=13:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[12].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l13()\n",
    "    if match>=14:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[13].text.strip('\\n').replace('\\n', ''))]=l14()\n",
    "    if match>=15:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[14].text.strip('\\n').replace('\\n', ''))]=l15()    \n",
    "    return a\n",
    "\n",
    "for i in range(0, len(list(dictinal2().keys()))):\n",
    "    booksheet.write(i+20,0,list(dictinal2().keys())[i])\n",
    "    booksheet.write(i+20,1,dictinal2()[list(dictinal2().keys())[i]][0])\n",
    "    booksheet.write(i+20,2,dictinal2()[list(dictinal2().keys())[i]][1])\n",
    "\n",
    "\n",
    "\n",
    "res= requests.get(\"http://sports.williamhill.com/bet/zh-hk/betting/g/614/%E7%B8%BD%E5%BE%97%E5%88%86.html\")\n",
    "soup=BeautifulSoup(res.text)\n",
    "\n",
    "\n",
    "match=len(soup.findAll(\"td\",{\"class\":\"CentrePad\"}))/2\n",
    "\n",
    "\n",
    "def l1():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[6].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[7].text[19:23])\n",
    "    return k\n",
    "\n",
    "def l2():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[8].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[9].text[19:23])\n",
    "    return k \n",
    "def l3():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[10].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[11].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l4():  \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[4].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[5].text[19:23])\n",
    "    return k \n",
    "    \n",
    "\n",
    "def l5(): \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[2].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[3].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l6():\n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[0].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[1].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "def l6():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[0].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[1].text[19:23]))\n",
    "    return k \n",
    "\n",
    "\n",
    "def l7():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[12].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[13].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "def l8():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[14].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[15].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l9():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[16].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[17].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l10():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[18].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[19].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l11():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[20].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[21].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "def l12():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[22].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[23].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l13():\n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[24].text[19:23]))\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[25].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "def dictinal3():\n",
    "    a=dict()\n",
    "    if match>=1:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0].text.strip('\\n').replace('\\n', ''))]=l6() \n",
    "    if match>=2:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2].text.strip('\\n').replace('\\n', ''))]=l5()     \n",
    "    if match>=3:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4].text.strip('\\n').replace('\\n', ''))]=l4()   \n",
    "    if match>=4:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[6].text.strip('\\n').replace('\\n', ''))]=l1()   \n",
    "    if match>=5:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[8].text.strip('\\n').replace('\\n', ''))]=l2()   \n",
    "    if match>=6:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[10].text.strip('\\n').replace('\\n', ''))]=l3()  \n",
    "    if match>=7:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[12].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l7() \n",
    "    if match>=8:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[14].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l8()     \n",
    "    if match>=9:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[16].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l9()   \n",
    "    if match>=10:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[18].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l10()   \n",
    "    if match>=11:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[20].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l11()   \n",
    "    if match>=12:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[22].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l12()  \n",
    "    if match>=13:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[24].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l13() \n",
    "    if match>=14:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[26].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l14()  \n",
    "    if match>=15:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[28].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l15()     \n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(list(dictinal3().keys()))):\n",
    "    booksheet.write(i+40,0,list(dictinal3().keys())[i])\n",
    "    booksheet.write(i+40,1,dictinal3()[list(dictinal3().keys())[i]][0])\n",
    "    booksheet.write(i+40,2,dictinal3()[list(dictinal3().keys())[i]][1])\n",
    "    booksheet.write(i+40,3,soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2*i+1].text)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "  \n",
    "workbook.save('mo1.xls') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'亞利桑那響尾蛇 (C Buchholz) @ 三藩市巨人 (C Stratton)': ['1.91', '1.91'],\n",
       " '密爾瓦基釀酒人 (C Anderson) @ 克里夫蘭印地安人 (C Carrasco)': ['1.87', '1.95'],\n",
       " '巴爾的摩金鶯 (D Bundy) @ 紐約大都會 (Z Wheeler)': ['1.95', '1.87'],\n",
       " '洛杉磯道奇 (C Ferguson) @ 匹兹堡海盗 (T Williams)': ['1.87', '1.95'],\n",
       " '科羅拉多洛磯 (J Gray) @ 辛辛那提紅人 (S Romano)': ['1.91', '1.91'],\n",
       " '紐約洋基 (S Gray) @ 多倫多藍鳥 (S Gaviglio)': ['1.95', '1.87']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictinal3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.findAll(\"td\",{\"class\":\"CentrePad\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
