{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hups\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\hups\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#改查詢\n",
    "import time\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "import xlwt\n",
    "import xlrd\n",
    "\n",
    "  \n",
    "workbook = xlwt.Workbook(encoding='utf-8')  \n",
    "booksheet = workbook.add_sheet('Sheet 1', cell_overwrite_ok=True)  \n",
    "#write dict\n",
    "\n",
    "\n",
    "\n",
    "res= requests.get(\"http://sports.williamhill.com/bet/zh-hk/betting/g/7267971/%E7%8D%A8%E8%B4%8F%E7%9B%A4.html\")\n",
    "soup=BeautifulSoup(res.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l1():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[6].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[7].text[19:23])\n",
    "    return k\n",
    "\n",
    "def l2():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[8].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[9].text[19:23])\n",
    "    return k \n",
    "def l3():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[10].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[11].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l4():  \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[4].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[5].text[19:23])\n",
    "    return k \n",
    "    \n",
    "\n",
    "def l5(): \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[2].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[3].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dictinal1():\n",
    "    a=dict()\n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0].text.strip('\\n').replace('\\n', ''))]=l6() \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[1]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[1].text.strip('\\n').replace('\\n', ''))]=l5()     \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2].text.strip('\\n').replace('\\n', ''))]=l4()   \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[3]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[3].text.strip('\\n').replace('\\n', ''))]=l1()   \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4].text.strip('\\n').replace('\\n', ''))]=l2()      \n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(list(dictinal1().keys()))):\n",
    "    booksheet.write(i,0,list(dictinal1().keys())[i])\n",
    "    booksheet.write(i,1,dictinal1()[list(dictinal1().keys())[i]][0])\n",
    "    booksheet.write(i,2,dictinal1()[list(dictinal1().keys())[i]][1])\n",
    "    \n",
    "    \n",
    "res= requests.get(\"http://sports.williamhill.com/bet/zh-hk/betting/g/7267972/%E8%AE%93%E5%88%86%E7%9B%A4.html\")\n",
    "soup=BeautifulSoup(res.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def l1():   \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[6].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[7].text[19:23]))\n",
    "    return k\n",
    "\n",
    "def l2():   \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[8].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[9].text[19:23]))\n",
    "    return k \n",
    "def l3():   \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[10].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[11].text[19:23]))\n",
    "    return k \n",
    "\n",
    "def l4():  \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[4].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[5].text[19:23]))\n",
    "    return k \n",
    "    \n",
    "\n",
    "def l5(): \n",
    "    k=[]\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[2].text[19:23]))\n",
    "    k.append(float(soup.findAll(\"div\",{\"class\":\"eventprice\"})[3].text[19:23]))\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dictinal2():\n",
    "    a=dict()\n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0]!=None:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l6() \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[1]!=None:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[1].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l5()     \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2]!=None:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l4()   \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[3]!=None:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[3].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l1()   \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4]!=None:\n",
    "        a[soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4].text.strip('\\n').replace('\\n', '').replace('\\t', '')]=l2()   \n",
    "    return a\n",
    "\n",
    "for i in range(0, len(list(dictinal2().keys()))):\n",
    "    booksheet.write(i+8,0,list(dictinal2().keys())[i])\n",
    "    booksheet.write(i+8,1,dictinal2()[list(dictinal2().keys())[i]][0])\n",
    "    booksheet.write(i+8,2,dictinal2()[list(dictinal2().keys())[i]][1])\n",
    "\n",
    "\n",
    "\n",
    "res= requests.get(\"http://sports.williamhill.com/bet/zh-hk/betting/g/7267973/%E7%B8%BD%E5%BE%97%E5%88%86.html\")\n",
    "soup=BeautifulSoup(res.text)\n",
    "\n",
    "\n",
    "\n",
    "def l1():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[6].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[7].text[19:23])\n",
    "    return k\n",
    "\n",
    "def l2():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[8].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[9].text[19:23])\n",
    "    return k \n",
    "def l3():   \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[10].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[11].text[19:23])\n",
    "    return k \n",
    "\n",
    "def l4():  \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[4].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[5].text[19:23])\n",
    "    return k \n",
    "    \n",
    "\n",
    "def l5(): \n",
    "    k=[]\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[2].text[19:23])\n",
    "    k.append(soup.findAll(\"div\",{\"class\":\"eventprice\"})[3].text[19:23])\n",
    "    return k \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dictinal3():\n",
    "    a=dict()\n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[0].text.strip('\\n').replace('\\n', ''))]=l6() \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2].text.strip('\\n').replace('\\n', ''))]=l5()     \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[4].text.strip('\\n').replace('\\n', ''))]=l4()   \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[6]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[6].text.strip('\\n').replace('\\n', ''))]=l1()   \n",
    "    if soup.findAll(\"td\",{\"class\":\"CentrePad\"})[8]!=None:\n",
    "        a[unicodedata.normalize(\"NFKD\", soup.findAll(\"td\",{\"class\":\"CentrePad\"})[8].text.strip('\\n').replace('\\n', ''))]=l2()   \n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(list(dictinal3().keys()))):\n",
    "    booksheet.write(i+16,0,list(dictinal3().keys())[i])\n",
    "    booksheet.write(i+16,1,dictinal3()[list(dictinal3().keys())[i]][0])\n",
    "    booksheet.write(i+16,2,dictinal3()[list(dictinal3().keys())[i]][1])\n",
    "    booksheet.write(i+16,3,soup.findAll(\"td\",{\"class\":\"CentrePad\"})[2*i+1].text)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dictinal3()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "  \n",
    "workbook.save('mo.xls') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KT巫師 對 起亞虎': ['1.85', '1.85'], 'LG雙子 對 韓華鷹': ['1.73', '2.00'], '尼克森英雄 對 鬥山熊': ['1.85', '1.85'], 'NC恐龍 對 樂天巨人': ['1.85', '1.85'], 'SK飛龍 對 三星獅': ['1.91', '1.80']}\n"
     ]
    }
   ],
   "source": [
    "print(dictinal3())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
